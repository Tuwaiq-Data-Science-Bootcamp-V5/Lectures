{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "035da0a8",
   "metadata": {},
   "source": [
    "##### Project Overview: This project for prediciting the next word depends on Hadith Dataset help us when we have right the hadith.\n",
    "##### Dataset: Hadith Dataset\n",
    "##### Link of dataset: https://www.kaggle.com/datasets/fahd09/hadith-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158e14d1",
   "metadata": {},
   "source": [
    "#### Goals: \n",
    "1. Help in writing hadith from Sunna with accuracy more than %65.\n",
    "2. Applied LSTM in this project\n",
    "\n",
    "#### Challenges:\n",
    "1. In Hadith Dataset it is quite challenging to get high percent accuracy because it is ambigous and have many different words with the same patteren such as:\n",
    "\n",
    "\"قال أبو بكر رضي الله عنه\",\n",
    "\n",
    "\"قال ابو سلمة رضي الله عنه\"\n",
    "\n",
    "..etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54576bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the important libraries\n",
    "\n",
    "# for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Preprocessing data\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Model\n",
    "from tensorflow.keras.models import Sequential # model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding # Layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a78508",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hadith_id</th>\n",
       "      <th>source</th>\n",
       "      <th>chapter_no</th>\n",
       "      <th>hadith_no</th>\n",
       "      <th>chapter</th>\n",
       "      <th>chain_indx</th>\n",
       "      <th>text_ar</th>\n",
       "      <th>text_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Revelation - كتاب بدء الوحى</td>\n",
       "      <td>30418, 20005, 11062, 11213, 11042, 3</td>\n",
       "      <td>حدثنا الحميدي عبد الله بن الزبير، قال حدثنا سف...</td>\n",
       "      <td>Narrated 'Umar bin Al-Khattab:          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Revelation - كتاب بدء الوحى</td>\n",
       "      <td>30355, 20001, 11065, 10511, 53</td>\n",
       "      <td>حدثنا عبد الله بن يوسف، قال أخبرنا مالك، عن هش...</td>\n",
       "      <td>Narrated 'Aisha:                        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Revelation - كتاب بدء الوحى</td>\n",
       "      <td>30399, 20023, 11207, 11013, 10511, 53</td>\n",
       "      <td>حدثنا يحيى بن بكير، قال حدثنا الليث، عن عقيل، ...</td>\n",
       "      <td>Narrated 'Aisha:                       (the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Revelation - كتاب بدء الوحى</td>\n",
       "      <td>11013, 10567, 34</td>\n",
       "      <td>قال ابن شهاب وأخبرني أبو سلمة بن عبد الرحمن، أ...</td>\n",
       "      <td>Narrated Jabir bin 'Abdullah Al-Ansari while ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Revelation - كتاب بدء الوحى</td>\n",
       "      <td>20040, 20469, 11399, 11050, 17</td>\n",
       "      <td>حدثنا موسى بن إسماعيل، قال حدثنا أبو عوانة، قا...</td>\n",
       "      <td>Narrated Said bin Jubair:               ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  hadith_id           source  chapter_no hadith_no  \\\n",
       "0   0          1   Sahih Bukhari            1        1    \n",
       "1   1          2   Sahih Bukhari            1        2    \n",
       "2   2          3   Sahih Bukhari            1        3    \n",
       "3   3          4   Sahih Bukhari            1        4    \n",
       "4   4          5   Sahih Bukhari            1        5    \n",
       "\n",
       "                       chapter                             chain_indx  \\\n",
       "0  Revelation - كتاب بدء الوحى   30418, 20005, 11062, 11213, 11042, 3   \n",
       "1  Revelation - كتاب بدء الوحى         30355, 20001, 11065, 10511, 53   \n",
       "2  Revelation - كتاب بدء الوحى  30399, 20023, 11207, 11013, 10511, 53   \n",
       "3  Revelation - كتاب بدء الوحى                       11013, 10567, 34   \n",
       "4  Revelation - كتاب بدء الوحى         20040, 20469, 11399, 11050, 17   \n",
       "\n",
       "                                             text_ar  \\\n",
       "0  حدثنا الحميدي عبد الله بن الزبير، قال حدثنا سف...   \n",
       "1  حدثنا عبد الله بن يوسف، قال أخبرنا مالك، عن هش...   \n",
       "2  حدثنا يحيى بن بكير، قال حدثنا الليث، عن عقيل، ...   \n",
       "3  قال ابن شهاب وأخبرني أبو سلمة بن عبد الرحمن، أ...   \n",
       "4  حدثنا موسى بن إسماعيل، قال حدثنا أبو عوانة، قا...   \n",
       "\n",
       "                                             text_en  \n",
       "0        Narrated 'Umar bin Al-Khattab:          ...  \n",
       "1        Narrated 'Aisha:                        ...  \n",
       "2   Narrated 'Aisha:                       (the m...  \n",
       "3   Narrated Jabir bin 'Abdullah Al-Ansari while ...  \n",
       "4        Narrated Said bin Jubair:               ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file through pandas\n",
    "df = pd.read_csv(\"hadith.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a5788b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34441 entries, 0 to 34440\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          34441 non-null  int64 \n",
      " 1   hadith_id   34441 non-null  int64 \n",
      " 2   source      34441 non-null  object\n",
      " 3   chapter_no  34441 non-null  int64 \n",
      " 4   hadith_no   34441 non-null  object\n",
      " 5   chapter     34441 non-null  object\n",
      " 6   chain_indx  34318 non-null  object\n",
      " 7   text_ar     34433 non-null  object\n",
      " 8   text_en     33588 non-null  object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Information of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54dc2b69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'حدثنا الحميدي عبد الله بن الزبير، قال حدثنا سفيان، قال حدثنا يحيى بن سعيد الأنصاري، قال أخبرني محمد بن إبراهيم التيمي، أنه سمع علقمة بن وقاص الليثي، يقول سمعت عمر بن الخطاب رضى الله عنه على المنبر قال سمعت رسول الله صلى الله عليه وسلم يقول \" إنما الأعمال بالنيات، وإنما لكل امرئ ما نوى، فمن كانت هجرته إلى دنيا يصيبها أو إلى امرأة ينكحها فهجرته إلى ما هاجر إليه \".'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace unrecognized symbols\n",
    "df[\"text_ar\"].replace(['\\u200f', '  '], [\"\", \" \"], regex= True, inplace = True)\n",
    "df[\"text_ar\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9ef671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assagin text_ar (arabic hadith) to corpus\n",
    "corpus = df[\"text_ar\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c21eccaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34441"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 34441 Hadith\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cc57a36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  72158\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer: create an index from each word in corpus\n",
    "# Create Instance of Tokenizer\n",
    "tokenizer = Tokenizer(oov_token='<oov>') # For those words which are not found in word_index\n",
    "# Fit the tokenizer variable with our text\n",
    "tokenizer.fit_on_texts(corpus) \n",
    "# build sequences of word using tokenizer\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "# Num of words\n",
    "num_classes = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Total number of words: \", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a6002a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we take the sequence and divide it into input and label \n",
    "# Example: \n",
    "# Input: [[0, 0, 0, 65, 45]]\n",
    "# Label: [[0, 0, 22, 65, 45]]\n",
    "\n",
    "input_sequences = []\n",
    "labels = []\n",
    "for sequence in sequences:\n",
    "    for i in range(1, len(sequence)):\n",
    "        n_gram_sequence = sequence[:i+1]\n",
    "        input_sequences.append(n_gram_sequence[:-1])\n",
    "        labels.append(n_gram_sequence[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a102a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the max_sequence_length by taking the max length of input_sequences\n",
    "# Then build a pad_sequence that make sure all sentences has the same lenth \n",
    "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9c880bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split our data to train and test\n",
    "\n",
    "split_ratio = 0.8 # 80% for the train\n",
    "split_index = int(split_ratio * len(input_sequences))\n",
    "x_train, y_train = input_sequences[:split_index], labels[:split_index]\n",
    "x_test, y_test = input_sequences[split_index:], labels[split_index:] # 20 for the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb942869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataGenerator is quite important when we have large number of data that can not store in your memory\n",
    "# or GPU Memory because of the large input \n",
    "# So DataGenerator not loads all of the data its like iterator, when you finshed of this data it throw it\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, tokenizer, sequences, labels, batch_size, max_sequence_length, num_classes):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = np.random.choice(len(self.sequences), size=self.batch_size, replace=False)\n",
    "        batch_sequences = [self.sequences[i] for i in batch_indices]\n",
    "        batch_labels = [self.labels[i] for i in batch_indices]\n",
    "        x = pad_sequences(batch_sequences, maxlen=self.max_sequence_length)\n",
    "        y = self.one_hot_encode(batch_labels)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def one_hot_encode(self, labels):\n",
    "        encoded_labels = np.zeros((len(labels), self.num_classes), dtype=np.float32)\n",
    "        for i, label in enumerate(labels):\n",
    "            encoded_labels[i, label] = 1.0\n",
    "        return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70754a40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = 20 # epochs\n",
    "batch_size = 64 # set the batch size\n",
    "\n",
    "# Data generator store the data in the memory but for not all the data\n",
    "# Works better when you have large amount of data\n",
    "train_data_generator = DataGenerator(tokenizer, x_train, y_train, batch_size, max_sequence_length, num_classes)\n",
    "test_data_generator = DataGenerator(tokenizer, x_test, y_test, batch_size, max_sequence_length, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3322eb28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 17:40:52.606697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22078 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:81:00.0, compute capability: 8.9\n",
      "2023-06-01 17:40:53.342224: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-01 17:40:53.343649: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-01 17:40:53.344547: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# Create the layers of the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_classes, output_dim=100, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(units=num_classes, activation='softmax')) # Last layer with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c980058e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26d0c25e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 17:42:11.526156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27961/27961 [==============================] - 2498s 89ms/step - loss: 4.7842 - accuracy: 0.3238\n",
      "Epoch 2/20\n",
      "27961/27961 [==============================] - 2285s 82ms/step - loss: 3.8308 - accuracy: 0.4090\n",
      "Epoch 3/20\n",
      "27961/27961 [==============================] - 2271s 81ms/step - loss: 3.3931 - accuracy: 0.4535\n",
      "Epoch 4/20\n",
      "27961/27961 [==============================] - 2250s 80ms/step - loss: 3.1186 - accuracy: 0.4922\n",
      "Epoch 5/20\n",
      "27961/27961 [==============================] - 2263s 81ms/step - loss: 2.9218 - accuracy: 0.5328\n",
      "Epoch 6/20\n",
      "27961/27961 [==============================] - 2263s 81ms/step - loss: 2.7811 - accuracy: 0.5891\n",
      "Epoch 7/20\n",
      "27961/27961 [==============================] - 2238s 80ms/step - loss: 2.6679 - accuracy: 0.6210\n",
      "Epoch 8/20\n",
      "27961/27961 [==============================] - 2233s 80ms/step - loss: 2.5699 - accuracy: 0.6518\n",
      "Epoch 9/20\n",
      "27961/27961 [==============================] - 2244s 80ms/step - loss: 2.4877 - accuracy: 0.6810\n",
      "Epoch 10/20\n",
      "27961/27961 [==============================] - 2225s 80ms/step - loss: 2.4224 - accuracy: 0.7079\n",
      "Epoch 11/20\n",
      "27961/27961 [==============================] - 2250s 80ms/step - loss: 2.3658 - accuracy: 0.7145\n",
      "Epoch 12/20\n",
      "27961/27961 [==============================] - 2249s 80ms/step - loss: 2.3122 - accuracy: 0.7299\n",
      "Epoch 13/20\n",
      "27961/27961 [==============================] - 2249s 80ms/step - loss: 2.2659 - accuracy: 0.7356\n",
      "Epoch 14/20\n",
      "27961/27961 [==============================] - 2234s 80ms/step - loss: 2.1243 - accuracy: 0.7406\n",
      "Epoch 15/20\n",
      "27961/27961 [==============================] - 2220s 79ms/step - loss: 1.9899 - accuracy: 0.7546\n",
      "Epoch 16/20\n",
      "27961/27961 [==============================] - 2249s 80ms/step - loss: 1.8558 - accuracy: 0.7689\n",
      "Epoch 17/20\n",
      "27961/27961 [==============================] - 2175s 78ms/step - loss: 1.6253 - accuracy: 0.7723\n",
      "Epoch 18/20\n",
      "27961/27961 [==============================] - 2146s 77ms/step - loss: 1.4022 - accuracy: 0.7845\n",
      "Epoch 19/20\n",
      "27961/27961 [==============================] - 2152s 77ms/step - loss: 1.1992 - accuracy: 0.7991\n",
      "Epoch 20/20\n",
      "27961/27961 [==============================] - 2154s 77ms/step - loss: 1.0541 - accuracy: 0.8009\n"
     ]
    }
   ],
   "source": [
    "# Using GPU train the data\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model.fit(train_data_generator, epochs=epoch, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5c32b37-6d28-4ee3-891b-945ae2f2675e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1822, 100)         7215800   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               117248    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 72158)             9308382   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,641,430\n",
      "Trainable params: 16,641,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "071df72f-f0a4-439d-9bce-6f909b59a5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "keras.models.save_model(model, \"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79e05db2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 06:34:46.190437: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-02 06:34:46.367143: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-02 06:34:46.368178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-02 06:34:46.369027: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990/6990 [==============================] - 265s 38ms/step - loss: 2.2767 - accuracy: 0.7363\n"
     ]
    }
   ],
   "source": [
    "# Test the data from test generator\n",
    "loss, accuracy = model.evaluate(test_data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff17484a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.27672815322876\n",
      "Accuracy: 0.7362821888923645\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3518dea",
   "metadata": {},
   "source": [
    "**I belive if we increase the number of epochs we will get better result like 50 epochs it will reach to more than 80%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ea4924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a1ef211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to predict next num of words\n",
    "def predict_next_word(seed_text, num_of_words):\n",
    "    for _ in range(num_of_words):\n",
    "        input_sequence = tokenizer.texts_to_sequences([seed_text])\n",
    "        input_sequence = pad_sequences(input_sequence, maxlen=max_sequence_length) \n",
    "        predictions = model.predict(input_sequence)\n",
    "\n",
    "        # Convert the predictions to words\n",
    "        predicted_word_index = predictions.argmax(axis=1)\n",
    "        predicted_word = tokenizer.index_word[predicted_word_index[0]]    \n",
    "        seed_text +=  ' ' + predicted_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dbac9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my choice of words\n",
    "seed_words = [\"رسول\", \"حذيفة\", \"محمد\", \"قال\", \"حديث\", \"عن\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2a48736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of seed_words\n",
    "\n",
    "import random\n",
    "samples = dict()\n",
    "\n",
    "for sen in seed_words:    \n",
    "    samples.update({sen: predict_next_word(sen, random.randint(2, 8))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c51fe7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>رسول</td>\n",
       "      <td>رسول الله بن عبد الله بن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>حذيفة</td>\n",
       "      <td>حذيفة بن نصر أبو توبة، عن ابن أبي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>محمد</td>\n",
       "      <td>محمد بن عمرو بن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>قال</td>\n",
       "      <td>قال أبو عيسى هذا حديث حسن صحيح وقد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>حديث</td>\n",
       "      <td>حديث حسن وقد روي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>عن</td>\n",
       "      <td>عن عمرو بن علي، قال حدثنا يحيى، عن عبيد</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start                                predicted\n",
       "0   رسول                 رسول الله بن عبد الله بن\n",
       "1  حذيفة        حذيفة بن نصر أبو توبة، عن ابن أبي\n",
       "2   محمد                          محمد بن عمرو بن\n",
       "3    قال       قال أبو عيسى هذا حديث حسن صحيح وقد\n",
       "4   حديث                         حديث حسن وقد روي\n",
       "5     عن  عن عمرو بن علي، قال حدثنا يحيى، عن عبيد"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe that contain the start word in the predicted sentence\n",
    "pd.DataFrame(samples.items(), columns=[\"start\", \"predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051bc9eb",
   "metadata": {},
   "source": [
    "#### <centeR> Thank You for Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3582e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
